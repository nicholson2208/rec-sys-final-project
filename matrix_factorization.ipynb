{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fee75e-6c5e-4bac-aed9-aa21e399c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062cc71c-724a-4c77-b589-f32d5b01aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_g_obj(file=\"adj_matrices/G_hci.pkl\"):\n",
    "#     with open(file, \"rb\") as pfile: \n",
    "#         G = pickle.load(pfile)\n",
    "    \n",
    "#     follows_at_least_10 = [person for person, out_degree in G.out_degree() if out_degree >= 10] \n",
    "    \n",
    "#     subgraph_hci = nx.subgraph(G, follows_at_least_10)\n",
    "    \n",
    "#     return subgraph_hci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a9a095-7b8c-47db-9b0d-602a5be4b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph_hci = read_g_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9bff76-f81c-40cf-a3b2-d45e5ffd7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_test/test.pkl\", \"rb\") as pfile:\n",
    "#     test = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61620dfe-de35-46bb-aced-986e914560ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_test/train.pkl\", \"rb\") as pfile:\n",
    "#     train = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ad8398-853a-43b1-9f92-6cd1dd7aaba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_test/anti_test.pkl\", \"rb\") as pfile:\n",
    "#     anti_test = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49672ddc-dbf7-4ae9-b6a2-00d44e51ab2d",
   "metadata": {},
   "source": [
    "### Factorization machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d522d25-b43e-4f8d-8a6a-2597158829e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/coreylynch/pyFM\n",
      "  Cloning https://github.com/coreylynch/pyFM to /tmp/pip-req-build-tnr7fyx2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/coreylynch/pyFM /tmp/pip-req-build-tnr7fyx2\n",
      "  Resolved https://github.com/coreylynch/pyFM to commit 0696c980993889a9429e4ab0b6c7dc8be6dac4de\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pyfm\n",
      "  Building wheel for pyfm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfm: filename=pyfm-0.0.0-cp310-cp310-linux_x86_64.whl size=65075 sha256=561d2006c161baad535d1ea595d9074af0745edacd9b72c6a6aba5e8822874f0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5rdcdj9/wheels/fa/5d/da/7f914f89db79e7442033d9c67bff7973fc17b514b7f379a4f7\n",
      "Successfully built pyfm\n",
      "Installing collected packages: pyfm\n",
      "Successfully installed pyfm-0.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/coreylynch/pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a621ced2-7784-428e-bac5-45539b94aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pyfm import pylibfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33daeba-5cb3-4208-882f-37f823993aa9",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba3b9b2-7e6a-49d1-ad16-b83488d602ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename,path=\"\", sample=1.0):\n",
    "    data = []\n",
    "    y = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            (index,user,item,rating)=line.split(',')\n",
    "            if random.random() <= sample:\n",
    "                data.append({ \"user\": str(user), \"item\": str(item)})\n",
    "                y.append(float(rating))\n",
    "                users.add(user)\n",
    "                items.add(item)\n",
    "\n",
    "    return (data, np.array(y), users, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27aa046d-2071-4261-9e8d-ca774b3d039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, y_train, train_users, train_items) = loadData(\"train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6807ad-24fe-4989-86cb-f959024e8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_data, y_test, test_users, test_items) = loadData(\"test_df.csv\") #contains both test and anti-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c05d11c-ada9-44d0-9138-730d5c7a9e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user': 'cqz', 'item': 'jbigham'},\n",
       " {'user': 'cqz', 'item': 'ryanatkn'},\n",
       " {'user': 'cqz', 'item': 'axz'},\n",
       " {'user': 'cqz', 'item': 'msbernst'},\n",
       " {'user': 'cqz', 'item': 'qli'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d154de7c-6ce0-4da7-85b1-bbd49852352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user': 'cqz', 'item': 'kentrellowens'},\n",
       " {'user': 'cqz', 'item': 'ruotongw'},\n",
       " {'user': 'cqz', 'item': 'schaferj'},\n",
       " {'user': 'Gillian', 'item': 'kgajos'},\n",
       " {'user': 'Gillian', 'item': 'andreaforte'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "751cbec5-0dfa-465d-b2b1-87f57c2abd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "#convert the combination_result to sets\n",
    "X_train_data_extended = [{'user': pair[0], 'item': pair[1]} for pair in permutations(list(train_users), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f13ed961-4c81-48f8-8ae7-ba0b37d7055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759512"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_data_extended) #this contains all the possible edge options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33f46611-ce9d-44bb-bf36-be519f512e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if value in train_data\n",
    "{'user': 'cqz', 'item': 'jbigham'} in X_train_data_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22dcdd94-e736-4014-a47a-409bdd28d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_extended_list = []\n",
    "\n",
    "for comb in X_train_data_extended:\n",
    "    if comb in train_data:\n",
    "        y_train_extended_list.append(1)\n",
    "    else:\n",
    "        y_train_extended_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b08ce48e-007b-400f-aa9b-01a086514b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759512"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_extended_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0125754-6293-4837-8aea-bd344e84d298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22480\n",
      "22480\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(y_train_extended_list.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "532d8a07-831c-4497-b90c-e0f048ac6c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759512\n",
      "759512\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_data_extended))\n",
    "print(len(y_train_extended_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27da8f0f-27db-46dc-a121-83aced1c1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to an array for pylib.FM\n",
    "y_train_data_extended = np.array(y_train_extended_list, dtype='double')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d7f82-6bcb-44d0-bd08-afc0d04c4736",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f53ee270-1eb7-4e96-87bf-048676e36bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DictVectorizer()\n",
    "X_train = v.fit_transform(X_train_data_extended)\n",
    "X_test = v.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a9da01-3f8a-47c7-866c-9ca26016dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.01335\n",
      "-- Epoch 2\n",
      "Training MSE: 0.01265\n",
      "-- Epoch 3\n",
      "Training MSE: 0.01253\n",
      "-- Epoch 4\n",
      "Training MSE: 0.01247\n",
      "-- Epoch 5\n",
      "Training MSE: 0.01244\n",
      "-- Epoch 6\n",
      "Training MSE: 0.01241\n",
      "-- Epoch 7\n",
      "Training MSE: 0.01239\n",
      "-- Epoch 8\n",
      "Training MSE: 0.01237\n",
      "-- Epoch 9\n",
      "Training MSE: 0.01236\n",
      "-- Epoch 10\n",
      "Training MSE: 0.01234\n"
     ]
    }
   ],
   "source": [
    "fm = pylibfm.FM (num_factors=10, \n",
    "                 num_iter=10, \n",
    "                 verbose=True, \n",
    "                 task=\"regression\", \n",
    "                 initial_learning_rate=0.001, \n",
    "                 learning_rate_schedule=\"optimal\")\n",
    "\n",
    "fm.fit(X_train, y_train_data_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87a6e8eb-67fe-4cbc-b8b0-846d6f8e635b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8096168309678552"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = fm.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426d876-9387-4dce-b569-8ca5ca6c404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c49c6b-34c6-48c1-810a-f1cc305bbb10",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9de082d8-1e83-43fe-8569-28ecaa633cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15d372d5-31b7-49b9-8973-f87413389017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserRecommendations:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.recs = []\n",
    "        \n",
    "    def add_entry(self, entry):\n",
    "        self.recs.append(entry)\n",
    "        \n",
    "    def select_top(self, k):\n",
    "        self.recs = sorted(self.recs, key=lambda entry: entry[2], reverse=True)\n",
    "        if len(self.recs) > k:\n",
    "            self.recs = self.recs[0:k]\n",
    "            \n",
    "        \n",
    "class TestRecommendations:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.test_recs = defaultdict(UserRecommendations)\n",
    "        \n",
    "    def setup(self, preds, k):\n",
    "        for entry in preds:\n",
    "            user = entry.uid\n",
    "            self.test_recs[user].add_entry(entry)\n",
    "                   \n",
    "        for user in self.test_recs.keys():\n",
    "            self.test_recs[user].select_top(k)\n",
    "            \n",
    "    def add_entry(self, user, entry):\n",
    "        self.test_recs[user].add_entry(entry)\n",
    "        \n",
    "    def select_top(self, user, k):\n",
    "        self.test_recs[user].select_top(k)\n",
    "            \n",
    "    def iter_recs(self):\n",
    "        for user in self.test_recs.keys():\n",
    "            yield (user, self.test_recs[user].recs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37d6725f-3b9a-4cee-b1b1-429676e4130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(ABC):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results_table = None\n",
    "        self.score = None\n",
    "        self.m_score = None\n",
    "        self.f_score = None\n",
    "        \n",
    "    def setup(self, trainset, testset):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluate_user(self, user, user_recs):\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, test_recs: TestRecommendations):\n",
    "        scores = []\n",
    "        self.results_table = {}\n",
    "        for user, recs in test_recs.iter_recs():\n",
    "            score = self.evaluate_user(user, recs)\n",
    "            scores.append(score)\n",
    "            self.results_table[user] = score\n",
    "        self.score = np.mean(scores)\n",
    "    \n",
    "    \n",
    "class ItemwiseEvaluator(Evaluator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def evaluate_user(self, user, user_recs):\n",
    "        return np.mean([self.evaluate_pred(rec) for rec in user_recs])\n",
    "        \n",
    "    @abstractmethod\n",
    "    def evaluate_pred(self, pred):\n",
    "        pass\n",
    "    \n",
    "class ListwiseEvaluator(Evaluator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluate_user(self, user, user_recs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16c468e8-e3f1-463c-91e0-11e6d30c08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDCGEvaluator(ListwiseEvaluator):\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        super().__init__()\n",
    "        self.rated_table = defaultdict(set)\n",
    "        self.idcg_table = {}\n",
    "        self.log_table = {}\n",
    "        self.list_len = k\n",
    "        self.users_g_lookup = dict()\n",
    "    \n",
    "    # compute idcg\n",
    "    def setup(self, trainset, testset):\n",
    "        for entry in testset:\n",
    "            self.rated_table[entry['user']].add(entry['item'])\n",
    "        idcg = 0\n",
    "        for i in range(0, self.list_len+1):\n",
    "            self.idcg_table[i] = idcg\n",
    "            rank_utility = 1 / np.log(i+2)\n",
    "            self.log_table[i] = rank_utility\n",
    "            idcg += rank_utility\n",
    "\n",
    "    \n",
    "    def evaluate_user(self, user, user_recs):  #called by evalueate\n",
    "        \n",
    "        dcg = 0.0\n",
    "        for i, pred in enumerate(user_recs):\n",
    "            if pred[1] in self.rated_table[user]:\n",
    "                dcg = self.log_table[i]\n",
    "        \n",
    "        idcg = 0\n",
    "        if len(self.rated_table[user]) >= self.list_len:\n",
    "               idcg = self.idcg_table[self.list_len]\n",
    "        else:\n",
    "               idcg = self.idcg_table[len(self.rated_table[user])]\n",
    "            \n",
    "        if idcg == 0:\n",
    "            return 0\n",
    "        return dcg/idcg\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5420068f-c09a-446f-9660-717200bbbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(20231110)\n",
    "\n",
    "def create_prediction_profiles(test_data, train_items, predict_list_len, frac=1.0):\n",
    "    train_items_lst = list(train_items) # Can't sample from a set\n",
    "    user_test_profile = defaultdict(set) # add the test data\n",
    "    for entry in test_data:\n",
    "        user_id = entry['user']\n",
    "        item_id = entry['item']\n",
    "        user_test_profile[user_id].add(item_id)\n",
    "    \n",
    "    test_users = list(user_test_profile.keys()) # sample from the test users\n",
    "    \n",
    "    test_users_select = random.sample(test_users, int(frac*len(test_users))) # create a big set and add the test users\n",
    "                      \n",
    "    user_predict_profile = {}\n",
    "    \n",
    "    for user in test_users_select:\n",
    "        profile = user_test_profile[user]\n",
    "        sample_items = list(random.sample(train_items_lst, predict_list_len + len(profile)))\n",
    "        sample_items = sample_items + list(profile)\n",
    "        user_predict_profile[user] = sample_items\n",
    "        \n",
    "    return user_predict_profile\n",
    "    \n",
    "# creating a list of recommendations for a user \n",
    "def create_test_recommendations(predict_fn, vectorizer, test_data, list_len, train_items, predict_list_len, frac=1.0):\n",
    "    user_predict_profile = create_prediction_profiles(test_data, train_items, predict_list_len, frac)\n",
    "    \n",
    "    trecs = TestRecommendations()\n",
    "    \n",
    "    # for all the usrs and items in the profile\n",
    "    for user, profile in user_predict_profile.items():\n",
    "        for item in profile:\n",
    "            x_test = vectorizer.transform({'user': user, 'item': item})\n",
    "            pred = predict_fn.predict(x_test)[0]\n",
    "            trecs.add_entry(user, (user, item, pred))\n",
    "        trecs.select_top(user, list_len)\n",
    "        \n",
    "    return trecs # return recommendations list for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9e62ea6-7cc0-4c25-82b3-73e74eb01fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_len = 10 # number of recommendations to return\n",
    "predict_list_len = 100\n",
    "frac = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69f820fe-aa51-4982-a1ab-7603e78a6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recs = create_test_recommendations(fm, v, test_data, list_len, train_items, predict_list_len, frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbcb772e-d863-465a-a892-15be4544fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ham',\n",
       "  [('ham', 'axz', 0.5428026143777659),\n",
       "   ('ham', 'andresmh', 0.45756005703787817),\n",
       "   ('ham', 'andresmh', 0.45756005703787817),\n",
       "   ('ham', 'jordant', 0.1921773300889609),\n",
       "   ('ham', 'depstein', 0.08467367505747984),\n",
       "   ('ham', 'reviewer2', 0.08235060794027185),\n",
       "   ('ham', 'haimson', 0.0788232255466597),\n",
       "   ('ham', 'juhokim', 0.07647523955884497),\n",
       "   ('ham', 'franziroesner', 0.06688551829899246),\n",
       "   ('ham', 'oulasvirta', 0.06682682010594126)]),\n",
       " ('annetropy',\n",
       "  [('annetropy', 'cfiesler', 0.4069386188927509),\n",
       "   ('annetropy', 'sigchi', 0.29718505658538735),\n",
       "   ('annetropy', 'carolinerpitt', 0.10750016370876184),\n",
       "   ('annetropy', 'katta', 0.09140284062502697),\n",
       "   ('annetropy', 'alextaylor', 0.07705169029665822),\n",
       "   ('annetropy', 'upol', 0.062462675771883996),\n",
       "   ('annetropy', 'justin', 0.06144226147565379),\n",
       "   ('annetropy', 'juchidiuno', 0.05779938881773508),\n",
       "   ('annetropy', 'garreth', 0.05508062036638522),\n",
       "   ('annetropy', 'landay', 0.04530548045091126)]),\n",
       " ('chitalyconf',\n",
       "  [('chitalyconf', 'axz', 0.6828745901242527),\n",
       "   ('chitalyconf', 'andresmh', 0.629130680484151),\n",
       "   ('chitalyconf', 'andresmh', 0.629130680484151),\n",
       "   ('chitalyconf', 'msbernst', 0.4892278910150952),\n",
       "   ('chitalyconf', 'floe', 0.3727136709607568),\n",
       "   ('chitalyconf', 'jordant', 0.3453124418752175),\n",
       "   ('chitalyconf', 'jordant', 0.3453124418752175),\n",
       "   ('chitalyconf', 'Heycori', 0.3327218603155911),\n",
       "   ('chitalyconf', 'Heycori', 0.3327218603155911),\n",
       "   ('chitalyconf', 'Niloufar', 0.32181275572760093)])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_recs.iter_recs())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b5ea0112-0787-43ec-9a7d-81a478605737",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg = NDCGEvaluator(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67390e7e-ff7c-4828-9eb0-500cd9484141",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg.setup(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b4d73a8-ced3-49ee-a1cc-2d513e6f4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg.evaluate(test_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cb19532-f970-4b98-93e8-d2807dc7e0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09090720906211562"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbaf97-6351-4c9f-ba31-45890a232fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
